# OMOAI Configuration
#
# Quick reference:
# - output.formats: [json, text, srt, vtt, md]
# - output.api_defaults.include: [transcript_raw, transcript_punct, segments]
# - output.api_defaults.summary: bullets | abstract | both | none
# - output.api_defaults.ts: none | s | ms | clock
# - api.default_response_format: json | text
#
# Tips:
# - Prefer excluding transcript_raw by default for privacy; include only when needed.
# - Keep api.default_response_format=json for machine consumers; use ?formats=text or Accept: text/plain for human-readable text.
# - To persist API outputs on disk, set output.save_on_api: true (saves final.json matching the API schema).

paths:
  chunkformer_dir: ./src/chunkformer
  chunkformer_checkpoint: ./models/chunkformer/chunkformer-large-vie
  out_dir: ./data/output

llm: &base_llm
  model_id: cpatonn/Qwen3-4B-Instruct-2507-AWQ-4bit
  quantization: auto
  max_model_len: 50000
  gpu_memory_utilization: 0.95
  max_num_seqs: 2
  max_num_batched_tokens: 8192
  trust_remote_code: false

asr:
  total_batch_duration_s: 3600 # 1 hour max (increased)
  chunk_size: 64
  left_context_size: 128
  right_context_size: 128
  device: auto
  autocast_dtype: fp16

punctuation:
  llm:
    <<: *base_llm
  # NOTE: preserve_original_words is currently unused by runtime; leave commented if desired
  # preserve_original_words: false
  auto_switch_ratio: 0.98
  auto_margin_tokens: 128
  # New behavior controls
  enable_paragraphs: true
  join_separator: " "
  paragraph_gap_seconds: 3.0
  system_prompt: |
    <instruction>
    Bạn là một chuyên gia biên tập tiếng Việt. Nhiệm vụ của bạn là sửa lỗi một cách tỉ mỉ cho văn bản đầu vào về ngữ pháp, chính tả, dấu câu và cách viết hoa.
    - Sửa tất cả các lỗi ngữ pháp và lỗi gõ máy (ví dụ: 'lai trim' -> 'livestream').
    - Chuyển các từ nước ngoài được phiên âm sang tiếng Việt về cách viết gốc của chúng (ví dụ: 'phây búc' -> 'Facebook').
    - Thêm tất cả các dấu câu cần thiết, bao gồm dấu phẩy, dấu chấm, dấu hỏi, v.v.
    - Sửa lỗi viết hoa cho đầu câu và danh từ riêng (ví dụ: 'hà nội' -> 'Hà Nội').
    - Đảm bảo giữ nguyên hoàn toàn từ ngữ, trật tự từ và ý nghĩa gốc ở những phần đã đúng ngữ pháp.
    - Đầu ra của bạn phải là một khối văn bản đã được sửa, liền mạch và không có gì khác.
    </instruction>
    <example>
    <input>xin chào thế giới đây là một ví dụ về khôi phục dấu câu</input>
    <output>Xin chào thế giới, đây là một ví dụ về khôi phục dấu câu.</output>
    </example>
    <example>
    <input>bạn tên là gì tôi tên là nam</input>
    <output>Bạn tên là gì? Tôi tên là Nam.</output>
    </example>
    <example>
    <input>tôi đang xem một buổi lai trim trên phây búc về trí tuệ nhân tạo ai</input>
    <output>Tôi đang xem một buổi livestream trên Facebook về trí tuệ nhân tạo AI.</output>
    </example>
    <example>
    <input>hôm qua tại hà nội thủ tướng đã nói chúng ta cần phải nỗ lực hơn nữa để phát triển kinh tế</input>
    <output>Hôm qua tại Hà Nội, Thủ tướng đã nói: "Chúng ta cần phải nỗ lực hơn nữa để phát triển kinh tế."</output>
    </example>
    <policy>
    QUY TẮC TUYỆT ĐỐI: Giữ nguyên 100% từ ngữ, cấu trúc câu và ý nghĩa gốc. Chỉ can thiệp để sửa các lỗi rõ ràng về ngữ pháp, chính tả, dấu câu và viết hoa. NGHIÊM CẤM viết lại câu, thay thế từ đồng nghĩa hoặc thay đổi văn phong của tác giả.
    </policy>
  user_prompt: "<input>{{TEXT_TO_CORRECT}}</input>"
  sampling:
    temperature: 0.0

summarization:
  llm:
    <<: *base_llm
  map_reduce: true
  auto_switch_ratio: 0.98
  auto_margin_tokens: 96
  system_prompt: |
    <instruction>
    Bạn là một chuyên gia phân tích nội dung. Nhiệm vụ của bạn là tạo một bản tóm tắt có cấu trúc, súc tích từ văn bản tiếng Việt được cung cấp.
    - Toàn bộ đầu ra phải bằng tiếng Việt.
    - Tạo một tiêu đề ngắn gọn, phù hợp.
    - Viết một đoạn tóm tắt ngắn (2-4 câu) nêu bật các điểm chính.
    - Liệt kê các ý chính quan trọng nhất dưới dạng danh sách gạch đầu dòng.
    - Đầu ra của bạn phải tuân theo định dạng được chỉ định và không có gì khác.

    Định dạng đầu ra BẮT BUỘC là:
    Tiêu đề: [Tiêu đề bạn tạo bằng tiếng Việt]
    Tóm tắt: [Tóm tắt bạn tạo bằng tiếng Việt]
    Điểm chính:
    - [Điểm chính 1]
    - [Điểm chính 2]
    - [...]
    </instruction>
    <example>
    <input>hôm nay trời đẹp tôi đi dạo công viên và gặp một người bạn cũ chúng tôi đã ngồi uống cà phê và nói chuyện về những kỷ niệm xưa</input>
    <output>
    Tiêu đề: Cuộc gặp gỡ trong công viên
    Tóm tắt: Tác giả tình cờ gặp lại một người bạn cũ khi đi dạo trong công viên. Cả hai đã cùng nhau uống cà phê và ôn lại những kỷ niệm xưa.
    Điểm chính:
    - Tác giả đi dạo công viên và tình cờ gặp lại bạn cũ.
    - Cả hai đã uống cà phê và trò chuyện về kỷ niệm.
    </output>
    </example>
    <example>
    <input>giá cổ phiếu của công ty công nghệ xyz đã tăng 15% trong phiên giao dịch hôm nay sau khi họ công bố báo cáo tài chính quý 3 với lợi nhuận vượt kỳ vọng của giới phân tích công ty cho biết sự tăng trưởng này đến từ mảng kinh doanh đám mây và trí tuệ nhân tạo</input>
    <output>
    Tiêu đề: Cổ Phiếu Công Ty XYZ Tăng Mạnh Sau Báo Cáo Tài Chính
    Tóm tắt: Công ty công nghệ XYZ chứng kiến giá cổ phiếu tăng vọt 15% nhờ báo cáo tài chính quý 3 có lợi nhuận cao hơn dự báo. Động lực tăng trưởng chính được xác định là từ mảng kinh doanh đám mây và trí tuệ nhân tạo.
    Điểm chính:
    - Giá cổ phiếu công ty XYZ tăng 15% trong một ngày.
    - Nguyên nhân là do báo cáo tài chính quý 3 vượt kỳ vọng.
    - Mảng đám mây và trí tuệ nhân tạo là động lực tăng trưởng chính.
    </output>
    </example>
    <example>
    <input>việt nam vừa phóng thành công vệ tinh nano dragon lên quỹ đạo bằng tên lửa epsilon 5 của nhật bản vệ tinh này có nhiệm vụ giám sát hoạt động tàu thuyền và tìm kiếm cứu nạn trên biển</input>
    <output>
    Tiêu đề: Việt Nam Phóng Thành Công Vệ Tinh NanoDragon
    Tóm tắt: Vệ tinh NanoDragon của Việt Nam đã được phóng thành công lên quỹ đạo từ Nhật Bản bằng tên lửa Epsilon 5. Vệ tinh sẽ thực hiện nhiệm vụ quan trọng là giám sát tàu thuyền và hỗ trợ các hoạt động tìm kiếm cứu nạn trên biển.
    Điểm chính:
    - Vệ tinh NanoDragon của Việt Nam đã được phóng thành công.
    - Vụ phóng được thực hiện tại Nhật Bản.
    - Phương tiện phóng là tên lửa Epsilon 5.
    - Nhiệm vụ của vệ tinh là giám sát hàng hải và hỗ trợ tìm kiếm cứu nạn.
    </output>
    </example>
    <policy>
    QUY TẮC TUYỆT ĐỐI: Đầu ra PHẢI bằng tiếng Việt.
    QUY TẮC TUYỆT ĐỐI: KHÔNG thêm thông tin không có trong văn bản gốc.
    QUY TẮC TUYỆT ĐỐI: KHÔNG bao gồm ý kiến hoặc diễn giải cá nhân.
    </policy>
  user_prompt: "<input>{{TEXT_TO_SUMMARIZE}}</input>"
  sampling:
    temperature: 0.7

timestamped_summary:
  llm:
    <<: *base_llm
  map_reduce: true
  auto_switch_ratio: 0.98
  auto_margin_tokens: 96
  return_raw: true
  system_prompt: |
    <instruction>
    Bạn là một trợ lý AI chuyên tạo danh sách các chủ đề chính từ một bản ghi có dấu thời gian. Người dùng sẽ cung cấp một bản ghi trong đó mỗi từ được đánh số và có dấu thời gian theo định dạng `[MM:SS] word`.

    Nhiệm vụ của bạn là xác định các chủ đề chính trong bản ghi và tạo một danh sách các chủ đề đó, mỗi chủ đề có dấu thời gian bắt đầu. Định dạng đầu ra phải là một danh sách, trong đó mỗi dòng chứa dấu thời gian bắt đầu của chủ đề, theo sau là một khoảng trắng và sau đó là tên chủ đề.

    Định dạng đầu ra BẮT BUỘC là:
    `[HH:MM:SS] [Tên chủ đề]`
    </instruction>
    <example>
    <input>
    1. [00:05] hôm 2. [00:08] nay 3. [00:10] chúng 4. [00:12] ta 5. [00:18] sẽ 6. [00:20] thảo 7. [00:21] luận 8. [00:28] về 9. [00:30] trí 10. [00:35] tuệ 11. [00:40] nhân 12. [00:42] tạo 13. [00:46] và 14. [00:50] học 15. [00:52] máy
    </input>
    <output>
    [00:00:30] Trí tuệ nhân tạo
    [00:00:50] Học máy
    </output>
    </example>
    <example>
    <input>
    1. [00:01] chào 2. [00:02] mừng 3. [00:03] đến 4. [00:04] với 5. [00:05] podcast 6. [00:06] của 7. [00:07] chúng 8. [00:08] tôi 9. [00:09] hôm 10. [00:10] nay 11. [00:11] chúng 12. [00:12] ta 13. [00:13] sẽ 14. [00:14] nói 15. [00:15] về 16. [00:16] blockchain 17. [00:17] và 18. [00:18] tiền 19. [00:19] điện 20. [00:20] tử
    </input>
    <output>
    [00:00:16] Blockchain và tiền điện tử
    </output>
    </example>
    # <policy>
    # QUY TẮC TUYỆT ĐỐI: Giữ nguyên định dạng đầu ra `[HH:MM:SS] [Tên chủ đề]`.
    # QUY TẮC TUYỆT ĐỐI: KHÔNG thêm thông tin không có trong văn bản gốc.
    # </policy>
  user_prompt: "<input>{{TEXT_TO_SUMMARIZE}}</input>"
  sampling:
    temperature: 0.2

output:
  # Legacy fields (maintained for backward compatibility)
  write_separate_files: true
  transcript_file: "transcript.txt" # Legacy - maps to transcript.file_punct
  summary_file: "summary.txt" # Legacy - maps to summary.file
  wrap_width: 0 # Legacy - maps to transcript.wrap_width

  # New structured configuration
  # Formats to generate on disk (script outputs). Valid values:
  # - json: always recommended; canonical data
  # - text: human-readable transcript/summary text files
  # - srt: SubRip subtitle file (requires segments)
  # - vtt: WebVTT subtitle file (requires segments)
  # - md: Markdown summaries/transcripts
  formats: ["json", "text", "srt", "vtt", "md"]

  # Transcript output configuration
  transcript:
    include_raw: true # Include raw transcript in outputs
    include_punct: true # Include punctuated transcript in outputs
    include_segments: true # Include timestamped segments in outputs
    # timestamps is currently unused by API; timed text writing is handled in scripts
    timestamps: "clock" # Format: "none", "s", "ms", "clock"
    wrap_width: 100 # Text wrapping width (0 = no wrapping)

    # Filename configuration
    file_raw: "transcript.raw.txt"
    file_punct: "transcript.punct.txt"
    file_srt: "transcript.srt"
    file_vtt: "transcript.vtt"
    file_segments: "segments.json"

  # Summary output configuration
  summary:
    # Default presentation for summaries written to disk (and fallback for API when api_defaults not set)
    # Valid values: bullets | abstract | both | none
    mode: "both"
    bullets_max: 7 # Maximum number of bullet points (API default)
    abstract_max_chars: 1000 # Currently unused by runtime
    language: "vi" # Summary language (passed through)
    file: "summary.md" # Summary output filename

  # Final output filename
  final_json: "final.json"

  # API-related output controls
  # If true, the API will persist per-request outputs to disk (final.json and optionally others)
  save_on_api: true

  # When save_on_api is true, which files to write. Valid values:
  # - final_json: canonical API-shaped JSON
  # - segments: segment list JSON
  # - transcripts: transcript.raw.txt / transcript.punct.txt (if available)
  save_formats_on_api:
    - final_json
    - segments

  # directory to save API outputs (overrides paths.out_dir when set)
  api_output_dir: "./data/output/api"

  # Default response content (applies when no query params are given)
  # Mirrors OutputFormatParams and lets you choose defaults for API responses
  # include: choose which fields to include by default. Valid values:
  #   - transcript_raw (sensitive; prefer excluding unless needed)
  #   - timestamped_summary
  #   - transcript_punct
  #   - segments
  # summary: bullets | abstract | both | none
  # ts: none | s | ms | clock  (controls timestamp formatting when returning timed formats)
  # include_quality_metrics: include WER/CER/PER metrics if available
  # include_diffs: include human-readable diffs if available
  # return_summary_raw: include raw LLM summary text if available
  api_defaults:
    include: ["summary", "transcript_punct", "timestamped_summary"] # include segments by default
    summary: "both" # bullets | abstract | both | none
    summary_bullets_max: 7
    summary_lang: "vi"
    include_quality_metrics: true
    include_diffs: false
    return_summary_raw: true
    # summary_fields: ["title", "abstract", "bullets", "raw"]
    # timestamped_summary_fields: ["summary_text", "timestamps", "raw"]

api:
  host: "0.0.0.0" # Use 127.0.0.1 for local-only dev
  port: 8000
  max_body_size_mb: 200 # Increased for longer audio files
  request_timeout_seconds: 1800 # 30 minutes to match ASR batch duration
  temp_dir: "/tmp"
  cleanup_temp_files: true
  # Stream subprocess logs and enable verbose script output
  stream_subprocess_output: true
  verbose_scripts: true
  enable_progress_output: true
  # Default response behavior for /v1/pipeline
  # - default_response_format: json | text
  # - allow_accept_override: if true, Accept: text/plain (without JSON) can switch to text
  # - allow_query_format_override: if true, ?formats=text can switch to text
  default_response_format: json
  allow_accept_override: true
  allow_query_format_override: true
  # service_mode removed; script-based pipeline is always used
  health_check_dependencies:
    - ffmpeg
    - config_file

logging:
  level: INFO
  format_type: structured # structured | json | simple
  enable_console: true
  enable_file: true
  log_file: "@logs/api_server.jsonl"
  # Optional human-readable text log alongside JSONL
  enable_text_file: true
  text_log_file: "@logs/api_server.log"
  max_file_size: 10485760 # 10 MB
  backup_count: 5
  # Advanced Loguru options (optional)
  rotation: "10 MB"
  retention: "14 days"
  compression: "gz"
  enqueue: true
  debug_mode: true
  quiet_mode: false

alignment:
  enabled: true
  language: vi
  device: auto
  return_char_alignments: false
  interpolate_method: nearest
  print_progress: true

vad:
  enabled: true
  method: silero # silero | webrtc | pyannote
  chunk_size: 30 # seconds, max speech window length (WhisperX default)
  overlap_s: 0.4 # seconds, window overlap to protect context
  vad_onset: 0.50 # WhisperX default
  vad_offset: 0.363 # WhisperX default
  min_speech_s: 0.30 # remove very short segments (s)
  min_silence_s: 0.30 # fill small gaps (s)
  device: auto # for torch-based methods
  hf_token_env: HUGGINGFACE_TOKEN
  webrtc:
    mode: 2 # 0..3 (2 balanced per common practice)
    frame_ms: 20 # 10/20/30 ms frames
    start_hangover_frames: 3
    end_hangover_frames: 5
  silero:
    threshold: 0.50
    min_speech_duration_ms: 250
    min_silence_duration_ms: 100
    max_speech_duration_s: 30
    speech_pad_ms: 30
    window_size_samples: 512
  pyannote:
    min_duration_on: 0.1
    min_duration_off: 0.1
    pad_onset: 0.0
    pad_offset: 0.0
